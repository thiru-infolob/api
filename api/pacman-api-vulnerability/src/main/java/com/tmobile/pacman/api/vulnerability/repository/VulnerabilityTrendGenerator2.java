/*******************************************************************************
 * Copyright 2018 T Mobile, Inc. or its affiliates. All Rights Reserved.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License.  You may obtain a copy
 * of the License at
 * 
 *   http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations under
 * the License.
 ******************************************************************************/
/**
  Copyright (C) 2017 T Mobile Inc - All Rights Reserve
  Purpose:
  Author :kkumar28
  Modified Date: Oct 20, 2017
  
 **/
package com.tmobile.pacman.api.vulnerability.repository;

import java.io.IOException;
import java.text.SimpleDateFormat;
import java.time.LocalDate;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.time.temporal.ChronoUnit;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

import org.apache.http.HttpEntity;
import org.apache.http.HttpHost;
import org.apache.http.client.config.RequestConfig;
import org.apache.http.entity.ContentType;
import org.apache.http.nio.entity.NStringEntity;
import org.apache.http.util.EntityUtils;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestClientBuilder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Repository;

import com.google.gson.Gson;
import com.google.gson.JsonArray;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParser;
import com.google.gson.reflect.TypeToken;
import com.tmobile.pacman.api.commons.Constants;
import com.tmobile.pacman.api.commons.exception.DataException;
import com.tmobile.pacman.api.commons.utils.PacHttpUtils;


/**
 * The Class VulnerabilityTrendGenerator.
 */
@Repository
public class VulnerabilityTrendGenerator2 implements Constants {

    /** The es host. */
    @Value("${elastic-search.host}")
    private String esHost;
    
    /** The es port. */
    @Value("${elastic-search.port}")
    private int esPort;
    
    /** The es cluster name. */
    @Value("${elastic-search.clusterName}")
    private String esClusterName;
    
    /** The date format. */
    @Value("${formats.date}")
    private String dateFormat;
        
    /** The Constant LOGGER. */
    private static final Logger LOGGER = LoggerFactory
            .getLogger(VulnerabilityTrendGenerator2.class);

    /**
     * Generate trend.
     *
     * @param ag the ag
     * @param severity the severity
     * @param fromDate the from date
     * @return the list
     * @throws Exception the exception
     */
   
    public List<Map<String, Object>> generateTrend(String ag,String severity, Date fromDate) throws Exception {
      
        List<Map<String, Object>> dateList = new ArrayList<>();
        LocalDate from = LocalDate.parse(new SimpleDateFormat("yyyy-MM-dd").format(fromDate));
       
       
       
        String queryBody = "\"query\":{\"bool\":{\"must\":[{\"terms\":{\"severitylevel.keyword\":["+severity+"]}}],\"should\":[{\"range\":{\"_closedate\":{\"gte\":\""+from+"\"}}},{\"match\":{\"_status\":\"open\"}}],\"minimum_should_match\":1}}";
        
        
        long totalCount = getTotalDocCount(ag,"vulninfo","{"+queryBody+"}");
        long start = System.currentTimeMillis();
        if (totalCount > 0) {
            
            
            ExecutorService executionService = Executors.newFixedThreadPool(2);
            Map<String,Long> newFoundMap = new HashMap<>();
            Map<String,Long> openCountMap = new HashMap<>();
          
          
            executionService.execute( () -> {
            	openCountMap.putAll(fetchVulnInfoDateRanges(ag,queryBody,from));
                            System.out.println("Time taken fetchVulnInfoDateRanges :"+(System.currentTimeMillis()-start));
                System.out.println("Time taken Date Grouping :"+(System.currentTimeMillis()-start));
                });
            
            executionService.execute(()-> {
                newFoundMap.putAll(fetchNewlyFoundVulnByDay(ag,severity,from));
                System.out.println("Time taken new Trend :"+(System.currentTimeMillis()-start));
            });
            
            executionService.shutdown();
            while(!executionService.isTerminated()){}
            
            
            
            openCountMap.entrySet().forEach(entry->{
                Map<String,Object> dateObj = new HashMap<>();
                String date = entry.getKey();
                Long open = entry.getValue();
                Long newlyFound = newFoundMap.get(date);
                
                dateObj.put("date",date);
                dateObj.put("open",open);
                dateObj.put("new",newlyFound==null?0l:newlyFound);
                dateList.add(dateObj);
                
            });
            System.out.println("Time taken Generate Trend :"+(System.currentTimeMillis()-start));
            return dateList ;
        } else {

            throw new DataException(NO_DATA_FOUND);
        }
    }
    
    /**
     * Fetch newly found vuln by day.
     *
     * @param ag the ag
     * @param severity the severity
     * @param from the from
     * @return the map
     */
    private Map<String,Long> fetchNewlyFoundVulnByDay(String ag,String severity,LocalDate from ){
        
        StringBuilder queryBody = new StringBuilder();
        queryBody.append("\"query\":{\"bool\":{\"must\":[").
            append("{\"terms\":{\"severitylevel.keyword\":["+severity+"]}}").
            append(",{\"range\":{\"_firstFound\":{\"gte\":\"").
            append(from.toString()).
            append("\"}}}]}}");
    
        String searchUrl = "http://"+esHost+":"+esPort+"/"+ag+"/vulninfo/_search?size=0";
        StringBuilder request = new StringBuilder();
        request.append("{").
            append("\"aggs\":{\"dates\":{\"date_histogram\":{\"field\":\"_firstFound\",\"interval\":\"day\",\"format\":\"yyyy-MM-dd\"}}}").
            append(",").append(queryBody).append("}");
        
        Map<String,Long> newFoundMap = new HashMap<>();
        try {
            String searchResponse = PacHttpUtils.doHttpPost(searchUrl, request.toString());
            JsonParser parser = new JsonParser();
            JsonObject responeObj = parser.parse(searchResponse).getAsJsonObject();
            JsonArray dateBuckets = responeObj.getAsJsonObject("aggregations").getAsJsonObject("dates").getAsJsonArray("buckets");
            for(JsonElement jsonElement:dateBuckets){
                JsonObject dateObj = jsonElement.getAsJsonObject();          
                newFoundMap.put(dateObj.get("key_as_string").getAsString(),dateObj.get("doc_count").getAsLong());
                
            }
        } catch (Exception e) {
            LOGGER.error("error",e);
        }   
        
        return newFoundMap;
    
    }
    
    /**
     * Fetch vuln info date ranges.
     *
     * @param ag the ag
     * @param scrollSize the scroll size
     * @param slices the slices
     * @param sliceNo the slice no
     * @param queryBody the query body
     * @param from the from
     * @return the list
     */
    private Map<String,Long> fetchVulnInfoDateRanges(String ag,String queryBody,LocalDate fromDate){
        //String searchUrl = "http://"+esHost+":"+esPort+"/"+ag+"/vulninfo/_search?scroll=2m&filter_path=hits.total,hits.hits._source,_scroll_id";
    	
    	System.out.println("Inside fetchVulnInfoDateRanges ");
    	long start = System.currentTimeMillis();
        String searchUrl = "/"+ag+"/vulninfo/_search";
        StringBuilder request = new StringBuilder();
        request.append("{\"size\":0,").
        append("\"aggs\": {\"from\": { \"terms\": { \"script\": \"new SimpleDateFormat('yyyy-MM-dd').format(doc['_firstFound'].value)\", \"size\": 10000},\"aggs\":"
        		+ " {  \"to\": {  \"terms\": {\"script\": \"new SimpleDateFormat('yyyy-MM-dd').format(doc['_closedate'].value)\",   \"size\": 10000 } }}}},").

        append(queryBody).append("}");
        
    	Map<String,Long> openCountMap = new ConcurrentHashMap<>();
        try{
       
        	String searchResponse = invokeESCall("GET",searchUrl, request.toString());   
        	System.out.println("****fetchVulnInfoDateRanges >> Time after ES Query"+ (System.currentTimeMillis()-start));
        	JsonParser parser = new JsonParser();
        	JsonObject responeObj = parser.parse(searchResponse).getAsJsonObject();
        	System.out.println("****fetchVulnInfoDateRanges >> Time took in ES query "+ responeObj.get("took").getAsString());
        	JsonArray fromBuckets = responeObj.getAsJsonObject("aggregations").getAsJsonObject("from").getAsJsonArray("buckets");
        	Map<String,Map<String,Long>> fromToMap = new HashMap<>();
        	for(JsonElement from : fromBuckets) {
        		JsonObject fromObj = (JsonObject)from;
        		String fromDt = fromObj.get("key").getAsString();
        		JsonArray toBukets = fromObj.getAsJsonObject("to").getAsJsonArray("buckets");
        		Map<String,Long> toList = new HashMap<>();
        		fromToMap.put(fromDt,toList);
        		for(JsonElement to : toBukets) {
        			JsonObject toObj = (JsonObject)to;
        			String toDt = toObj.get("key").getAsString();
        			long count = toObj.get("doc_count").getAsLong();
        			if("1969-12-31".equals(toDt)) {
        				toDt = null;
        			}
        			toList.put(toDt,count);
        		}
        	}
        	
        	System.out.println("****fetchVulnInfoDateRanges >> Time after Parsing Result"+ (System.currentTimeMillis()-start));
        
        	fromToMap.forEach((from,v)-> {
        		v.forEach((to,count)-> {
        			List<String> ranges =  getDateRange(from,to,fromDate,DateTimeFormatter.ofPattern("yyyy-MM-dd"));
        			ranges.parallelStream().forEach(date -> {
        					Long currentVal = openCountMap.get(date);
        					openCountMap.put(date,currentVal==null?count:(currentVal+count));
        				}
        			);
        		});
            
        	});
        	
        	System.out.println("****fetchVulnInfoDateRanges >> Time after Finding date range "+ (System.currentTimeMillis()-start));
        		
        }catch(Exception e){
            LOGGER.error("error",e);
            openCountMap.clear();
        }
        
        return  openCountMap;
        
    }
    
    
    private  List<Map<String,Object>> scrollAndFetch(String searchUrl, String requestBody){
        List<Map<String,Object>> hitsList = new ArrayList<>();
        String uri = searchUrl;
        String request = requestBody;
        String searchResponse ;
        JsonParser parser = new JsonParser();  
        JsonObject responeObj ;
        long total ;
        String scrollId ;
        JsonArray hits;
        //String scrollUri ="http://"+esHost+":"+esPort+"/_search/scroll";
        String scrollUri ="/_search/scroll?filter_path=hits.total,hits.hits._source,_scroll_id";
        String scrollRequest = "{\"scroll\":\"2m\",\"scroll_id\":\"%s\"}";
        try{
            do{
                
                //searchResponse = PacHttpUtils.doHttpPost(uri, request);   
                searchResponse = invokeESCall("GET",uri, request);   
                parser = new JsonParser();
                responeObj = parser.parse(searchResponse).getAsJsonObject();
                scrollId = responeObj.get("_scroll_id").getAsString();
                total = responeObj.getAsJsonObject("hits").get("total").getAsLong();
                hits = responeObj.getAsJsonObject("hits").getAsJsonArray("hits");
                hitsList.addAll(new Gson().fromJson(hits,new TypeToken<List<Map<String,Object>>>(){}.getType()));
                uri = scrollUri ;
                request = String.format(scrollRequest, scrollId);
                //System.out.println("SCROLL:"+total+":"+hitsList.size());
                if(hits.size()==0) break;
            }while(total>hitsList.size());
        }catch(Exception e){
            //System.out.println(uri);
            //System.out.println(request);
            LOGGER.error("error",e);
        }
        
        return hitsList;
    }
    
    /**
     * Gets the total doc count.
     *
     * @param ag the ag
     * @param type the type
     * @param queryBody the query body
     * @return the total doc count
     * @throws DataException the data exception
     */
    private long getTotalDocCount(String ag, String type, String queryBody) throws DataException{
        String countUrl = "http://"+esHost+":"+esPort+"/"+ag+"/"+type+"/_count";
        String countResponse = "";
        try {
            countResponse = PacHttpUtils.doHttpPost(countUrl, queryBody);
        } catch (Exception e) {
            throw new DataException(e);
        }   
        JsonParser jsonParser = new JsonParser();
        JsonObject response = jsonParser.parse(countResponse).getAsJsonObject();
        return Double.valueOf(response.get("count").getAsString()).longValue();
       
    }

    /**
     * Gets the date range.
     *
     * @param from the from
     * @param to the to
     * @param excludeBefore the exclude before
     * @param inputFormatter the input formatter
     * @return the date range
     */
    private List<String> getDateRange(Object from, Object to, LocalDate excludeBefore, DateTimeFormatter inputFormatter){
        LocalDate fromDt;
        LocalDate toDt;
        List<String> dateRage = new ArrayList<>();
        if(from!=null){
            fromDt = LocalDate.parse(from.toString(),inputFormatter);
            if(fromDt.isBefore(excludeBefore)) {
            	fromDt = excludeBefore;
            }
            if(to==null){
                toDt = LocalDate.now();
            }else{
                toDt = LocalDate.parse(to.toString(),inputFormatter);
            }
            DateTimeFormatter formatter = DateTimeFormatter.ISO_LOCAL_DATE;
            int daysBetween = (int) ChronoUnit.DAYS.between(fromDt, toDt);
            
            for(int i=0;i<daysBetween;i++ ) {
            	dateRage.add(formatter.format(fromDt.plusDays(i)));
             };
        }
        return dateRage;
    }
    
   
   
    /**
     * Fetch assets date ranges for ec 2.
     *
     * @param ag the ag
     * @param from the from
     * @param isAssetsAffected the is assets affected
     * @return the list
     * @throws DataException the data exception
     */
    public Map<String, Long> fetchAssetsDateRangesForEc2(String ag, LocalDate from) throws DataException {
        String searchUrl = "/"+ag+"/ec2/_search?filter_path=aggregations.resources.buckets.key,aggregations.resources.buckets.from.buckets.key,aggregations.resources.buckets.from.buckets.to.buckets.key,took";
        StringBuilder queryBody = new StringBuilder();
        queryBody.append("\"query\":{\"range\": {\"discoverydate.keyword\": {\"gte\":\""+from+"\"}}}");
        long totalCount = getTotalDocCount(ag,"ec2","{"+queryBody.toString()+"}");
        StringBuilder request = new StringBuilder();
        request.append("{\"size\":0,").
        append("\"aggs\": { \"resources\": {\"terms\": {\"field\": \"_resourceid.keyword\",  \"size\": 1000000},\"aggs\": { \"from\": {\"terms\": { \"script\": \"doc['firstdiscoveredon.keyword'].value.substring(0,10)\", \"size\": 10000 }, \"aggs\": {  \"to\": {  \"terms\": { \"script\": \"doc['discoverydate.keyword'].value.substring(0,10)\",\"size\": 10000}} }}} }} ,").
        append(queryBody).append("}");
        
        Map<String, Long> dateResourceCountMap = new HashMap<>();
        
        if (totalCount > 0) {
    
         	long start = System.currentTimeMillis();
            try{
             	String searchResponse = invokeESCall("GET",searchUrl, request.toString());   
             	System.out.println("****fetchAssetsDateRangesForEc2 >> Time after ES Query"+ (System.currentTimeMillis()-start));
             	dateResourceCountMap = findResoucerDistributionByDate(searchResponse,from);
                 
            }catch(Exception e){
                LOGGER.error("error",e);
               
            }
           
        }
        return dateResourceCountMap;
    }
    
    /**
     * Fetch assets date ranges on prem.
     *
     * @param ag the ag
     * @param from the from
     * @param isAssetsAffected the is assets affected
     * @return the list
     * @throws DataException the data exception
     */
    @SuppressWarnings("unchecked")
    public List<String> fetchAssetsDateRangesOnPrem(String ag, LocalDate from) throws DataException {
        
        List<String> dates = new ArrayList<>();
        String searchUrl = "/"+ag+"/onpremserver/_search?scroll=2m&filter_path=hits.total,hits.hits._source,_scroll_id";
        StringBuilder queryBody = new StringBuilder();
        queryBody.append("\"query\":{\"bool\":{\"must\":[{\"script\":{\"script\":\"")
                .append("LocalDate.parse(doc['discoverydate.keyword'].value.substring(0,10)).isAfter(LocalDate.of(").append(from.getYear()+","+from.getMonthValue()+","+from.getDayOfMonth()).append("))")
                .append("|| ( !doc['last_discovered.keyword'].empty  && LocalDate.parse(doc['last_discovered.keyword'].value.substring(0,10)).isAfter(LocalDate.of(").append(from.getYear()+","+from.getMonthValue()+","+from.getDayOfMonth()).append(")))")
                .append("\"}}")
                .append("]}}");
        long totalCount = getTotalDocCount(ag,"onpremserver","{"+queryBody.toString()+"}");
        if (totalCount > 0) {
            final int scrollSize = totalCount > 10000 ? 10000
                    : (int) (totalCount / 2) + 1;
            
            final int slices = totalCount > scrollSize ? (int) totalCount
                    / scrollSize + 1 : 2;
       
            IntStream.range(0, slices)
                .parallel().forEach(i -> {
                    StringBuilder request = new StringBuilder("{\"size\":").append(scrollSize);
                    request.append(",\"_source\":[\"_resourceid\",\"first_discovered\",\"firstdiscoveredon\",\"discoverydate\"],");
                    request.append("\"slice\": {\"id\":").append(i).append(",\"max\":").append(slices).append("},").append(queryBody).append("}");
              
                    List<String> onpremDatesList = new ArrayList<>();
                    try{
                        List<Map<String,Object>> hitsList = scrollAndFetch(searchUrl,request.toString());
                        List<Map<String,Object>> docs = new ArrayList<>();
                        hitsList.parallelStream().forEach(hit -> {
                            Map<String,Object> doc = (Map<String,Object>)hit.get("_source");
                            if(doc.get("first_discovered") != null) {
                                doc.put(Constants.FIRST_DISCOVERED_ON, doc.get("first_discovered"));
                            }
                            
                            synchronized(docs){
                                docs.add(doc);
                            }
                        });
                        
                        onpremDatesList = docs.parallelStream().flatMap(obj-> 
                            getDateRange(obj.get(Constants.FIRST_DISCOVERED_ON).toString().substring(0,10),obj.get("discoverydate").toString().substring(0,10),
                                from,DateTimeFormatter.ofPattern("yyyy-MM-dd"))
                                    .stream()).collect(Collectors.toList());
                        
                    }catch(Exception e){
                        LOGGER.error("Error in fetchAssetsDateRangesOnPrem",e);
                    }
                    synchronized(dates){
                        dates.addAll(onpremDatesList);
                    }
                 });
        }
        return dates;
    }
    
    /**
     * Fetch assets date ranges on prem.
     *
     * @param ag the ag
     * @param from the from
     * @param isAssetsAffected the is assets affected
     * @return 
     * @return the list
     * @throws DataException the data exception
     */
    public Map<String,Long> fetchAssetsAffected(String ag, LocalDate from,String severity) throws DataException {
        String queryBody = "\"query\":{\"bool\":{\"must\":[{\"terms\":{\"severitylevel.keyword\":["+severity+"]}}],\"should\":[{\"range\":{\"_closedate\":{\"gte\":\""+from+"\"}}},{\"match\":{\"_status\":\"open\"}}],\"minimum_should_match\":1}}";
        
        long totalCount = getTotalDocCount(ag,"vulninfo","{"+queryBody+"}");

        if (totalCount > 0) {
           return fetchVulnInfoDateRangesPerResource(ag,queryBody,from);
        }
        return new HashMap<>();
     
    }
    
    
    /**
     * Fetch vuln info date ranges.
     *
     * @param ag the ag
     * @param scrollSize the scroll size
     * @param slices the slices
     * @param sliceNo the slice no
     * @param queryBody the query body
     * @param from the from
     * @return the list
     */
    private Map<String,Long> fetchVulnInfoDateRangesPerResource(String ag,String queryBody,LocalDate fromDate){
    	
    	String searchUrl = "/"+ag+"/vulninfo/_search?filter_path=aggregations.resources.buckets.key,aggregations.resources.buckets.from.buckets.key,aggregations.resources.buckets.from.buckets.to.buckets.key,took";
        StringBuilder request = new StringBuilder();
        request.append("{\"size\":0,").
        append("\"aggs\": { \"resources\": {\"terms\": {\"field\": \"_resourceid.keyword\",  \"size\": 1000000},\"aggs\": { \"from\": {\"terms\": { \"script\": \"new SimpleDateFormat('yyyy-MM-dd').format(doc['_firstFound'].value)\", \"size\": 10000 }, \"aggs\": {  \"to\": {  \"terms\": { \"script\": \"new SimpleDateFormat('yyyy-MM-dd').format(doc['_closedate'].value)\",\"size\": 10000}} }}} }} ,").
        append(queryBody).append("}");
        
     	Map<String, Long> dateResourceCountMap = new  ConcurrentHashMap<>();
     	long start = System.currentTimeMillis();
        try {
         	String searchResponse = invokeESCall("GET",searchUrl, request.toString());   
         	System.out.println("****fetchVulnInfoDateRangesPerResource >> Time after ES Query"+ (System.currentTimeMillis()-start));
         	dateResourceCountMap = findResoucerDistributionByDate(searchResponse,fromDate);
      
         	System.out.println("****Time after Parsing Result"+ (System.currentTimeMillis()-start));     
        }catch(Exception e){
            LOGGER.error("error",e);
           
        }
        return dateResourceCountMap;
      
    }
    /**
     * Return the resoruce distribution based on the aggregated results
     *  
     * The response follows the nested aggreation on resources > fromDate > ToDate
     * 
     * @param searchResponse
     * @return
     */
    private  Map<String,Long> findResoucerDistributionByDate(String searchResponse,LocalDate fromDate){
    	JsonParser parser = new JsonParser();
     	JsonObject responeObj = parser.parse(searchResponse).getAsJsonObject();
     	System.out.println("****Time taken for ES Query "+responeObj.get("took").getAsLong());
     	JsonArray resourceBuckets = responeObj.getAsJsonObject("aggregations").getAsJsonObject("resources").getAsJsonArray("buckets");
    	Map<String,Set<String>> dateResourceMap = new  ConcurrentHashMap<>();

     	for(JsonElement resourceElmnt : resourceBuckets) {
     		JsonObject resourceObj = (JsonObject)resourceElmnt;
     		String resource = resourceObj.get("key").getAsString();
     		
     		JsonArray fromBukets = resourceObj.getAsJsonObject("from").getAsJsonArray("buckets");
     		
     		for(JsonElement from : fromBukets) {
     			JsonObject fromObj = (JsonObject)from;
     			String fromDt = fromObj.get("key").getAsString();
     		
     			JsonArray toBukets = fromObj.getAsJsonObject("to").getAsJsonArray("buckets");
     			for(JsonElement to : toBukets) {
     				JsonObject toObj = (JsonObject)to;
         			String toDt = toObj.get("key").getAsString();
         			if("1969-12-31".equals(toDt)) {
         				toDt = null;
         			}
         			List<String> ranges =  getDateRange(fromDt,toDt,fromDate,DateTimeFormatter.ofPattern("yyyy-MM-dd"));
         			ranges.parallelStream().forEach(date -> {
         					Set<String> currentResources = dateResourceMap.get(date);
         					if(currentResources==null) {
         						currentResources = new HashSet<>();
         						dateResourceMap.put(date, currentResources);
         					}
         					
         					currentResources.add(resource);
         					
         				}
         			);
         		
     			}
     			
     		}
     	}
     	return dateResourceMap.entrySet().parallelStream().collect(Collectors.toMap(entry->entry.getKey(), entry-> Long.valueOf(""+entry.getValue().size())));
    }
    
    private RestClient getRestClient() {
            RestClientBuilder builder = RestClient.builder(new HttpHost(esHost, esPort));
            builder.setRequestConfigCallback(new RestClientBuilder.RequestConfigCallback() {
                @Override
                public RequestConfig.Builder customizeRequestConfig(RequestConfig.Builder requestConfigBuilder) {
                    return requestConfigBuilder.setConnectionRequestTimeout(0).setSocketTimeout(60000);
                }
            }).setMaxRetryTimeoutMillis(60000);
            return builder.build();
    }

    private String invokeESCall(String method, String endpoint, String payLoad) {
        
        HttpEntity entity = null;
        try {
            if (payLoad != null) {
                entity = new NStringEntity(payLoad, ContentType.APPLICATION_JSON);
            }
            return EntityUtils.toString(getRestClient()
                    .performRequest(method, endpoint, Collections.<String, String>emptyMap(), entity).getEntity());
        } catch (IOException e) {
            LOGGER.error("Error in invokeESCall ", e);
        }
        return null;
    }
}
